{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Table Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 환경을 불러온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-09 21:46:03,112] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-Table 학습 알고리즘 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 모든 가능한 상태(observation_space)와 행동(action_space)에 대해 표의 모든 값을 0으로 초기화한다. \n",
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "# 학습 파라미터를 설정한다\n",
    "# lr 은 학습률\n",
    "lr = .85\n",
    "# y은 gamma, 할인률 미래 보상에 대해 얼마나 할인할 것인가\n",
    "y = .99\n",
    "# 에피소드 수 2000번 수행\n",
    "num_episodes = 2000\n",
    "# 에피소드의 각 걸음(step)과 총 보상을 저장하려는 리스트를 만든다\n",
    "#jList = []\n",
    "# 에피소드의 보상을 모음\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    # 첫 상태를 초기화한다 env.reset()\n",
    "    s = env.reset()\n",
    "    # 총 보상 rAll\n",
    "    rAll = 0\n",
    "    # 끝났는지를 나타내는 d 변수\n",
    "    d = False\n",
    "    # 걸음 수는 j\n",
    "    j = 0\n",
    "    # Q 러닝 알고리즘\n",
    "    # 99걸음까지만 허용함\n",
    "    while j < 99:\n",
    "        # 걸음마다 더해줌\n",
    "        j+=1\n",
    "        # Q table에서 e -greedy 에 따라 가장 좋은 행동을 선택함 매 걸음마다 랜덤적 요소를 넣음\n",
    "        # 1/ (i+1) 을 넣는 이유는 에피소드가 진행될 수록 랜덤적 요소를 줄이려고 하는 것임\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
    "        # env.step은 주어진 행동에 대한 다음 상태와 보상, 끝났는지 여부, 추가정보를 제공함\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        #새로 얻은 보상을 바탕으로 이전의 Q table을 업데이트함\n",
    "        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n",
    "        # 에피소드 총 보상에서 더해줌\n",
    "        rAll += r\n",
    "        # 상태를 다음 상태로 바꿈\n",
    "        s = s1\n",
    "        # 끝에 도달하면 다음 에피소드로 넘어감\n",
    "        if d == True:\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    # 에피소드별 총 보상을 모음\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.673\n"
     ]
    }
   ],
   "source": [
    "print (\"Score over time: \" +  str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41% 정도 성공한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table Values\n",
      "[[ 0.771  0.015  0.015  0.015]\n",
      " [ 0.002  0.002  0.     0.589]\n",
      " [ 0.     0.339  0.003  0.002]\n",
      " [ 0.002  0.     0.002  0.411]\n",
      " [ 0.828  0.005  0.002  0.   ]\n",
      " [ 0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.07   0.   ]\n",
      " [ 0.     0.     0.     0.   ]\n",
      " [ 0.006  0.006  0.     0.916]\n",
      " [ 0.006  0.945  0.     0.   ]\n",
      " [ 0.982  0.     0.003  0.001]\n",
      " [ 0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.963  0.   ]\n",
      " [ 0.     0.995  0.     0.   ]\n",
      " [ 0.     0.     0.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Q-Table Values\")\n",
    "print (np.round(Q,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
